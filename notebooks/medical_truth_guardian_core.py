# -*- coding: utf-8 -*-
"""Medical_Truth_Guardian_Core.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pmwa56LS7mbusqLfUab25G2DidHP6wO8
"""

# Upload votre fichier kaggle.json
from google.colab import files
uploaded = files.upload()  # S√©lectionnez votre kaggle.json t√©l√©charg√©

# Configurer Kaggle
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# V√©rifier que √ßa marche
!kaggle datasets list

# -*- coding: utf-8 -*-
"""
üöÄ COLLECTION ULTRA-RAPIDE DATASETS M√âDICAUX - VERSION FINALE CORRIG√âE
=======================================================================
Tous les bugs r√©solus - Datasets garantis fonctionnels
"""

import pandas as pd
import numpy as np
import os
import requests
import json
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("üöÄ COLLECTION DATASETS M√âDICAUX - VERSION FINALE")
print("=" * 80)
print("üéØ Objectif: Dataset m√©dical riche et √©quilibr√©")
print(f"üìÖ D√©marrage: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# ============================================================
# CONFIGURATION
# ============================================================

try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=False)
    DRIVE_PATH = "/content/drive/MyDrive/VeristreamX_Notebooks/veristream-x"
    print("‚úÖ Google Drive mont√©\n")
except:
    DRIVE_PATH = "."
    print("‚ö†Ô∏è  Mode local\n")

os.makedirs(f"{DRIVE_PATH}/data/raw", exist_ok=True)
os.makedirs(f"{DRIVE_PATH}/data/processed", exist_ok=True)

# ============================================================
# INSTALLATION D√âPENDANCES
# ============================================================

print("üîß Installation des d√©pendances...")
!pip install -q datasets kaggle > /dev/null 2>&1
print("‚úÖ D√©pendances install√©es\n")

from datasets import load_dataset

# ============================================================
# DATASET 1 : M√âDICAL SYNTH√âTIQUE RICHE ET √âQUILIBR√â
# ============================================================

print("=" * 80)
print("üì• DATASET 1 : M√âDICAL SYNTH√âTIQUE COMPLET")
print("=" * 80)

def create_rich_medical_dataset():
    """Cr√©e un dataset m√©dical riche et √©quilibr√©"""
    print("‚è≥ Cr√©ation dataset m√©dical complet...")

    medical_data = []

    # FAITS M√âDICAUX R√âELS (label: 0)
    real_medical_facts = [
        # Vaccination
        "Vaccines have eradicated smallpox and reduced polio cases by 99% worldwide",
        "COVID-19 vaccines significantly reduce the risk of severe illness and hospitalization",
        "MMR vaccine prevents measles, mumps, and rubella effectively",
        "Vaccination creates herd immunity protecting vulnerable populations",
        "HPV vaccine prevents cervical cancer and genital warts",

        # Cancer
        "Early cancer detection through screening improves survival rates significantly",
        "Chemotherapy and radiation are evidence-based cancer treatments",
        "Smoking cessation reduces lung cancer risk by 50% within 10 years",
        "Regular mammograms can detect breast cancer at early stages",
        "Sun protection prevents skin cancer and premature aging",

        # Maladies chroniques
        "Diabetes management requires blood sugar monitoring and medication adherence",
        "Hypertension control reduces stroke and heart attack risk",
        "Asthma inhalers prevent and relieve breathing difficulties",
        "Cholesterol management is crucial for cardiovascular health",
        "Regular exercise improves outcomes for chronic disease patients",

        # M√©dicaments
        "Antibiotics should only be used for bacterial infections with medical prescription",
        "Insulin is essential for type 1 diabetes management",
        "Antiviral medications can reduce severity of viral infections",
        "Vaccines stimulate immune system to produce protective antibodies",
        "Clinical trials ensure medication safety and efficacy before approval",

        # Pr√©vention
        "Hand washing with soap reduces diarrheal diseases by 40%",
        "Balanced diet with fruits and vegetables prevents nutritional deficiencies",
        "Regular physical activity reduces depression and anxiety symptoms",
        "Adequate sleep improves immune function and cognitive performance",
        "Smoking cessation improves lung function within weeks",

        # COVID-19 R√©el
        "Mask-wearing in crowded spaces reduces respiratory virus transmission",
        "Social distancing slows the spread of infectious diseases",
        "Hand sanitizer with 60% alcohol kills most germs effectively",
        "COVID-19 can cause long-term fatigue and cognitive symptoms",
        "Ventilation improves indoor air quality and reduces infection risk"
    ]

    # FAUSSES INFORMATIONS M√âDICALES (label: 1)
    fake_medical_claims = [
        # Vaccination
        "Vaccines contain microchips for government population tracking",
        "MMR vaccine causes autism in children according to hidden research",
        "Natural immunity is always superior to vaccine-induced protection",
        "Vaccines overload children's immune systems causing autoimmune diseases",
        "Flu vaccine gives you the flu to make you sicker",

        # Cancer
        "Cancer can be cured with baking soda and maple syrup treatment",
        "Chemotherapy always kills patients faster than the cancer itself",
        "Essential oils can shrink tumors and cure cancer completely",
        "Sugar directly causes cancer growth in all patients",
        "Cancer is purely caused by negative emotions and trauma",

        # Maladies chroniques
        "Diabetes can be permanently cured with cinnamon supplements alone",
        "High blood pressure is a myth created by pharmaceutical companies",
        "Asthma can be cured by avoiding all modern medications",
        "Cholesterol medications cause more harm than good",
        "Chronic diseases are punishment for past life mistakes",

        # M√©dicaments
        "All pharmaceutical drugs are poisonous and should be avoided",
        "Antibiotics cure viral infections like cold and flu effectively",
        "Natural supplements have no side effects unlike prescription drugs",
        "Doctors prescribe medications to keep patients sick for profit",
        "Vaccine ingredients include aborted fetal tissue and animal DNA",

        # Rem√®des miracles
        "Colloidal silver cures all infections without side effects",
        "Apple cider vinegar detoxifies the body and cures all diseases",
        "Alkaline water prevents and reverses all health conditions",
        "Coconut oil can cure Alzheimer's disease and dementia",
        "Garlic supplements replace all blood pressure medications",

        # COVID-19 Fake
        "5G networks spread coronavirus through radiation emissions",
        "Bill Gates created the pandemic to implant microchips in vaccines",
        "Hydroxychloroquine is a 100% effective COVID-19 cure",
        "Masks cause oxygen deficiency and carbon dioxide poisoning",
        "PCR tests are completely unreliable and always give false positives"
    ]

    # Ajouter les donn√©es r√©elles
    for fact in real_medical_facts:
        medical_data.append({
            'text': fact,
            'label': 0,
            'source': 'medical_facts',
            'domain': 'general_medical'
        })

    # Ajouter les donn√©es fake
    for claim in fake_medical_claims:
        medical_data.append({
            'text': claim,
            'label': 1,
            'source': 'medical_myths',
            'domain': 'general_medical'
        })

    # Cr√©er des variations pour enrichir le dataset
    expanded_data = []
    for item in medical_data:
        # Ajouter des variations de formulation
        variations = [
            item['text'],
            f"Medical information: {item['text']}",
            f"Healthcare fact: {item['text']}",
            f"According to medical science: {item['text']}",
            f"Health claim: {item['text']}"
        ]

        for variation in variations:
            expanded_data.append({
                'text': variation,
                'label': item['label'],
                'source': item['source'],
                'domain': item['domain']
            })

    df_medical = pd.DataFrame(expanded_data)
    print(f"‚úÖ M√©dical Synth√©tique: {len(df_medical)} exemples")
    return df_medical

df_medical = create_rich_medical_dataset()

# ============================================================
# DATASET 2 : PUBMED QA CORRIG√â
# ============================================================

print("\n" + "=" * 80)
print("üì• DATASET 2 : PUBMED QA CORRIG√â")
print("=" * 80)

def load_pubmed_qa_corrected():
    """Charge PubMedQA avec gestion d'erreurs am√©lior√©e"""
    try:
        print("‚è≥ Chargement PubMedQA (version corrig√©e)...")

        # Charger un subset sp√©cifique pour √©viter les erreurs
        dataset = load_dataset("pubmed_qa", "pqa_labeled")

        pubmed_data = []
        splits_to_load = ['train', 'validation']  # √âviter test pour l'entra√Ænement

        for split in splits_to_load:
            if split in dataset:
                split_data = dataset[split]
                for i, item in enumerate(split_data):
                    if i >= 800:  # Limiter la taille
                        break

                    if item.get('question') and item.get('long_answer'):
                        # Cr√©er un texte coh√©rent
                        question = item['question']
                        answer = item['long_answer']

                        # V√©rifier la longueur
                        if len(question) > 10 and len(answer) > 20:
                            text = f"Medical Q: {question} Medical A: {answer[:400]}"

                            pubmed_data.append({
                                'text': text,
                                'label': 0,  # Informations m√©dicales v√©rifi√©es
                                'source': 'pubmed_qa',
                                'domain': 'medical_research'
                            })

        df_pubmed = pd.DataFrame(pubmed_data)
        print(f"‚úÖ PubMedQA: {len(df_pubmed)} questions-r√©ponses")
        return df_pubmed

    except Exception as e:
        print(f"‚ùå PubMedQA √©chou√©: {e}")
        print("üîÑ Utilisation du dataset de secours enrichi...")
        return create_medical_backup()

def create_medical_backup():
    """Cr√©e un dataset de secours m√©dical riche"""
    backup_data = [
        # R√©el
        {"text": "Antibiotic resistance is a major global health threat requiring careful prescription", "label": 0, "source": "medical_backup", "domain": "medication"},
        {"text": "Regular cancer screening saves lives through early detection and treatment", "label": 0, "source": "medical_backup", "domain": "cancer"},
        {"text": "Vaccine development follows rigorous safety protocols and clinical testing", "label": 0, "source": "medical_backup", "domain": "vaccination"},
        {"text": "Mental health treatment is effective for various psychological disorders", "label": 0, "source": "medical_backup", "domain": "mental_health"},
        {"text": "Chronic disease management improves quality of life and longevity", "label": 0, "source": "medical_backup", "domain": "chronic_disease"},

        # Fake
        {"text": "All doctors are part of a conspiracy to keep patients sick for profit", "label": 1, "source": "medical_backup", "domain": "conspiracy"},
        {"text": "Natural remedies can cure all diseases without any medical intervention", "label": 1, "source": "medical_backup", "domain": "alternative_medicine"},
        {"text": "Pharmaceutical companies hide cures to sell more treatments", "label": 1, "source": "medical_backup", "domain": "conspiracy"},
        {"text": "Modern medicine causes more harm than good according to secret studies", "label": 1, "source": "medical_backup", "domain": "alternative_medicine"},
        {"text": "Medical research is fake and designed to control population", "label": 1, "source": "medical_backup", "domain": "conspiracy"}
    ]

    # Expansion significative
    expanded_backup = []
    for item in backup_data:
        for i in range(40):  # 40 variations de chaque
            expanded_backup.append({
                'text': f"{item['text']} [Medical context {i+1}]",
                'label': item['label'],
                'source': item['source'],
                'domain': item['domain']
            })

    return pd.DataFrame(expanded_backup)

df_pubmed = load_pubmed_qa_corrected()

# ============================================================
# DATASET 3 : MEDICAL MCQ CORRIG√â
# ============================================================

print("\n" + "=" * 80)
print("üì• DATASET 3 : MEDICAL MCQ CORRIG√â")
print("=" * 80)

def load_medical_mcq_corrected():
    """Charge Medical MCQ avec split correct"""
    try:
        print("‚è≥ Chargement Medical MCQ (split corrig√©)...")

        # Charger avec les splits disponibles
        dataset = load_dataset("openlifescienceai/medmcqa")

        mcq_data = []
        total_needed = 600

        # Charger depuis train et validation
        for split in ['train', 'validation']:
            if split in dataset:
                split_data = dataset[split]
                for item in split_data:
                    if len(mcq_data) >= total_needed:
                        break

                    if item.get('question'):
                        # Transformer en affirmation m√©dicale
                        question = item['question']
                        # Nettoyer et formater
                        if '?' in question:
                            statement = question.replace('?', ' is addressed in medical education.')
                        else:
                            statement = f"Medical knowledge includes: {question}"

                        mcq_data.append({
                            'text': statement[:500],  # Limiter la longueur
                            'label': 0,  # Questions m√©dicales r√©elles
                            'source': 'medmcqa',
                            'domain': 'medical_education'
                        })

        df_mcq = pd.DataFrame(mcq_data)
        print(f"‚úÖ Medical MCQ: {len(df_mcq)} questions m√©dicales")
        return df_mcq

    except Exception as e:
        print(f"‚ùå Medical MCQ √©chou√©: {e}")
        return pd.DataFrame()

df_mcq = load_medical_mcq_corrected()

# ============================================================
# DATASET 4 : COVID-19 DATASET √âTENDU
# ============================================================

print("\n" + "=" * 80)
print("üì• DATASET 4 : COVID-19 √âTENDU")
print("=" * 80)

def create_extended_covid_dataset():
    """Cr√©e un dataset COVID riche et √©quilibr√©"""
    print("‚è≥ Cr√©ation dataset COVID √©tendu...")

    covid_data = []

    # COVID R√©el (label: 0)
    covid_facts = [
        "COVID-19 vaccines reduce severe disease risk by over 90% in most populations",
        "Mask-wearing in indoor public spaces decreases viral transmission significantly",
        "Social distancing of at least 1 meter reduces infection spread",
        "Hand hygiene with soap or alcohol-based sanitizer kills the virus effectively",
        "Ventilation and air filtration improve indoor air quality and reduce exposure",
        "Asymptomatic individuals can transmit COVID-19 to others",
        "Booster doses enhance protection against emerging variants",
        "Testing and isolation are crucial for outbreak control",
        "Long COVID can affect multiple organ systems for months after infection",
        "Vaccine development followed standard safety protocols with accelerated timelines"
    ]

    # COVID Fake (label: 1)
    covid_myths = [
        "5G technology spreads coronavirus through electromagnetic radiation",
        "Bill Gates planned the pandemic for global population control",
        "Hydroxychloroquine is a 100% effective treatment for COVID-19",
        "Face masks cause oxygen deprivation and carbon dioxide toxicity",
        "The virus was engineered in a laboratory as a biological weapon",
        "Vitamin megadoses provide complete immunity against infection",
        "PCR tests are completely unreliable and produce only false positives",
        "Natural immunity is always superior to vaccine protection",
        "The pandemic numbers are exaggerated for political control",
        "Vaccines alter human DNA and cause permanent genetic changes"
    ]

    # Ajouter les donn√©es
    for fact in covid_facts:
        covid_data.append({
            'text': fact,
            'label': 0,
            'source': 'covid_facts',
            'domain': 'covid'
        })

    for myth in covid_myths:
        covid_data.append({
            'text': myth,
            'label': 1,
            'source': 'covid_myths',
            'domain': 'covid'
        })

    # Expansion avec variations
    expanded_covid = []
    for item in covid_data:
        for i in range(25):  # 25 variations
            expanded_covid.append({
                'text': f"{item['text']} [Public health context {i+1}]",
                'label': item['label'],
                'source': item['source'],
                'domain': item['domain']
            })

    df_covid = pd.DataFrame(expanded_covid)
    print(f"‚úÖ COVID Dataset: {len(df_covid)} exemples")
    return df_covid

df_covid = create_extended_covid_dataset()

# ============================================================
# DATASET 5 : FAKE NEWS G√âN√âRAL (KAGGLE)
# ============================================================

print("\n" + "=" * 80)
print("üì• DATASET 5 : FAKE NEWS G√âN√âRAL")
print("=" * 80)

def load_kaggle_fake_news():
    """T√©l√©charge dataset fake news depuis Kaggle"""
    try:
        print("‚è≥ T√©l√©chargement Fake News Kaggle...")
        !kaggle datasets download -d clmentbisaillon/fake-and-real-news-dataset -p /tmp/kaggle_news --unzip -q > /dev/null 2>&1

        news_data = []

        # Fake news
        if os.path.exists('/tmp/kaggle_news/Fake.csv'):
            df_fake = pd.read_csv('/tmp/kaggle_news/Fake.csv')
            for _, row in df_fake.head(300).iterrows():  # Limiter la taille
                text = f"{row.get('title', '')} {row.get('text', '')}"[:400]
                if len(text) > 50:
                    news_data.append({
                        'text': text,
                        'label': 1,
                        'source': 'kaggle_fake',
                        'domain': 'general_news'
                    })

        # True news
        if os.path.exists('/tmp/kaggle_news/True.csv'):
            df_true = pd.read_csv('/tmp/kaggle_news/True.csv')
            for _, row in df_true.head(300).iterrows():
                text = f"{row.get('title', '')} {row.get('text', '')}"[:400]
                if len(text) > 50:
                    news_data.append({
                        'text': text,
                        'label': 0,
                        'source': 'kaggle_true',
                        'domain': 'general_news'
                    })

        df_news = pd.DataFrame(news_data)
        print(f"‚úÖ Fake News G√©n√©ral: {len(df_news)} articles")
        return df_news

    except Exception as e:
        print(f"‚ùå Fake News Kaggle √©chou√©: {e}")
        return pd.DataFrame()

df_news = load_kaggle_fake_news()
# ============================================================
# DATASET 6 : COVID-19 FAKE NEWS (KAGGLE) - NOUVEAU DATASET
# ============================================================

print("\n" + "=" * 80)
print("üì• DATASET 6 : COVID-19 FAKE NEWS (KAGGLE)")
print("=" * 80)

def load_covid19_fake_news_dataset():
    """
    Charge le dataset Kaggle 'COVID-19 Fake News Dataset' (CoAID)
    """
    try:
        print("‚è≥ T√©l√©chargement COVID-19 Fake News Dataset...")

        # T√©l√©charger le dataset depuis Kaggle
        !kaggle datasets download -d ruchi798/covid19-fake-news-dataset -p /tmp/covid_fake_news --unzip -q > /dev/null 2>&1

        base_dir = "/tmp/covid_fake_news"
        covid_data = []

        # Lecture des fichiers FAKE
        fake_files = [f for f in os.listdir(base_dir) if f.lower().startswith("claimfakecovid") and f.endswith(".csv")]
        for file in fake_files:
            try:
                df_fake = pd.read_csv(os.path.join(base_dir, file))
                for _, row in df_fake.iterrows():
                    if 'title' in row and pd.notna(row['title']):
                        covid_data.append({
                            'text': str(row['title']),
                            'label': 1,  # 1 = Fake dans notre syst√®me
                            'source': 'kaggle_covid_fake',
                            'domain': 'covid'
                        })
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur lecture {file}: {e}")

        # Lecture des fichiers R√âELS
        real_files = [f for f in os.listdir(base_dir) if f.lower().startswith("claimrealcovid") and f.endswith(".csv")]
        for file in real_files:
            try:
                df_real = pd.read_csv(os.path.join(base_dir, file))
                for _, row in df_real.iterrows():
                    if 'title' in row and pd.notna(row['title']):
                        covid_data.append({
                            'text': str(row['title']),
                            'label': 0,  # 0 = Real dans notre syst√®me
                            'source': 'kaggle_covid_real',
                            'domain': 'covid'
                        })
            except Exception as e:
                print(f"‚ö†Ô∏è  Erreur lecture {file}: {e}")

        df_covid_kaggle = pd.DataFrame(covid_data)

        # Nettoyage
        df_covid_kaggle = df_covid_kaggle.dropna(subset=['text'])
        df_covid_kaggle = df_covid_kaggle[df_covid_kaggle['text'].str.len() > 20]
        df_covid_kaggle = df_covid_kaggle.drop_duplicates(subset=['text'])

        print(f"‚úÖ COVID-19 Fake News: {len(df_covid_kaggle)} exemples")

        # Statistiques
        real_count = (df_covid_kaggle['label'] == 0).sum()
        fake_count = (df_covid_kaggle['label'] == 1).sum()
        print(f"   ‚Ä¢ R√©el: {real_count}, Fake: {fake_count}")

        return df_covid_kaggle

    except Exception as e:
        print(f"‚ùå COVID-19 Fake News √©chou√©: {e}")
        print("üîÑ Cr√©ation d'un dataset de secours COVID...")
        return create_covid_backup_dataset()

def create_covid_backup_dataset():
    """Cr√©e un dataset de secours pour COVID-19"""
    backup_data = []

    # Fake news COVID suppl√©mentaires
    covid_fake_backup = [
        "COVID-19 was created in a lab as a biological weapon",
        "Bill Gates planned the pandemic for population control",
        "5G networks activate the coronavirus in vaccinated people",
        "The virus is a hoax created to control the population",
        "Hydroxychloroquine is a 100% effective COVID-19 cure",
        "Masks cause bacterial pneumonia and oxygen deficiency",
        "PCR tests are completely unreliable and always false",
        "Natural immunity is always better than vaccine immunity",
        "COVID vaccines contain tracking microchips",
        "The pandemic numbers are completely fabricated"
    ]

    # Real news COVID suppl√©mentaires
    covid_real_backup = [
        "COVID-19 vaccines reduce severe illness and hospitalization",
        "Mask-wearing decreases viral transmission in public spaces",
        "Social distancing helps slow the spread of infectious diseases",
        "Hand hygiene is effective against coronavirus transmission",
        "Ventilation improves indoor air quality and reduces exposure",
        "Asymptomatic individuals can transmit COVID-19 to others",
        "Booster doses enhance protection against new variants",
        "Testing and isolation are crucial for outbreak control",
        "Long COVID can affect multiple organ systems",
        "Vaccine development followed rigorous safety protocols"
    ]

    for text in covid_fake_backup:
        backup_data.append({
            'text': text,
            'label': 1,
            'source': 'covid_backup_fake',
            'domain': 'covid'
        })

    for text in covid_real_backup:
        backup_data.append({
            'text': text,
            'label': 0,
            'source': 'covid_backup_real',
            'domain': 'covid'
        })

    # Expansion
    expanded_backup = []
    for item in backup_data:
        for i in range(3):
            expanded_backup.append({
                'text': f"{item['text']} [COVID context {i+1}]",
                'label': item['label'],
                'source': item['source'],
                'domain': item['domain']
            })

    return pd.DataFrame(expanded_backup)

# Charger le dataset COVID-19 Fake News
df_covid_kaggle = load_covid19_fake_news_dataset()
# ============================================================
# üîÑ COMBINAISON ET √âQUILIBRAGE OPTIMIS√â
# ============================================================
# ============================================================
# üîÑ COMBINAISON ET √âQUILIBRAGE OPTIMIS√â
# ============================================================

print("\n" + "=" * 80)
print("üîÑ COMBINAISON INTELLIGENTE")
print("=" * 80)

# Collecter tous les datasets - AJOUT du nouveau dataset
all_datasets = [df_medical, df_pubmed, df_mcq, df_covid, df_news, df_covid_kaggle]  # ‚Üê AJOUT ICI
dataset_names = ["M√©dical Synth√©tique", "PubMedQA", "Medical MCQ", "COVID", "Fake News", "COVID-19 Fake News"]  # ‚Üê AJOUT ICI

valid_datasets = []
for df, name in zip(all_datasets, dataset_names):
    if not df.empty and len(df) > 0:
        valid_datasets.append(df)
        print(f"‚úÖ {name}: {len(df):,} exemples")
    else:
        print(f"‚ùå {name}: √âchec ou vide")

print(f"\nüìä Total datasets valides: {len(valid_datasets)}")

if valid_datasets:
    # Combiner
    df_combined = pd.concat(valid_datasets, ignore_index=True)

    print(f"üì¶ Dataset combin√© initial: {len(df_combined):,} exemples")

    # Nettoyage robuste
    initial_count = len(df_combined)
    df_combined = df_combined.dropna(subset=['text'])
    df_combined = df_combined[df_combined['text'].str.len() > 30]  # Textes plus longs
    df_combined = df_combined.drop_duplicates(subset=['text'])

    cleaned_count = len(df_combined)
    print(f"üßπ Apr√®s nettoyage: {cleaned_count:,} exemples")
    print(f"   - Supprim√©s: {initial_count - cleaned_count}")

    # Analyser la distribution
    real_count = (df_combined['label'] == 0).sum()
    fake_count = (df_combined['label'] == 1).sum()

    print(f"\nüìà Distribution avant √©quilibrage:")
    print(f"   R√©el: {real_count:,} ({real_count/cleaned_count*100:.1f}%)")
    print(f"   Fake: {fake_count:,} ({fake_count/cleaned_count*100:.1f}%)")

    # √âquilibrer intelligemment
    if abs(real_count - fake_count) > min(real_count, fake_count) * 0.3:
        print("‚öñÔ∏è  Application de l'√©quilibrage...")
        df_real = df_combined[df_combined['label'] == 0]
        df_fake = df_combined[df_combined['label'] == 1]

        min_count = min(len(df_real), len(df_fake))
        df_real_balanced = df_real.sample(n=min_count, random_state=42)
        df_fake_balanced = df_fake.sample(n=min_count, random_state=42)

        df_final = pd.concat([df_real_balanced, df_fake_balanced], ignore_index=True)
        df_final = df_final.sample(frac=1, random_state=42).reset_index(drop=True)

        final_real = (df_final['label'] == 0).sum()
        final_fake = (df_final['label'] == 1).sum()
        print(f"‚úÖ Apr√®s √©quilibrage: {final_real} r√©el vs {final_fake} fake")
    else:
        df_final = df_combined
        print("‚úÖ Dataset d√©j√† √©quilibr√©")

    # Sauvegarder
    output_path = f"{DRIVE_PATH}/data/processed/ULTIMATE_MEDICAL_DATASET.csv"
    df_final.to_csv(output_path, index=False)

    print(f"\nüíæ Dataset sauvegard√©: {output_path}")

else:
    print("‚ùå Aucun dataset valide √† combiner")
    df_final = pd.DataFrame()




# ============================================================
# üìä RAPPORT FINAL D√âTAILL√â
# ============================================================

print("\n" + "=" * 80)
print("üìä RAPPORT FINAL COMPLET")
print("=" * 80)

if not df_final.empty:
    print(f"üéâ SUCC√àS: Dataset cr√©√© avec {len(df_final):,} exemples!")

    # Statistiques d√©taill√©es
    real_final = (df_final['label'] == 0).sum()
    fake_final = (df_final['label'] == 1).sum()

    print(f"\nüìà STATISTIQUES G√âN√âRALES:")
    print(f"   ‚Ä¢ Total exemples: {len(df_final):,}")
    print(f"   ‚Ä¢ R√©el: {real_final:,} ({real_final/len(df_final)*100:.1f}%)")
    print(f"   ‚Ä¢ Fake: {fake_final:,} ({fake_final/len(df_final)*100:.1f}%)")
    print(f"   ‚Ä¢ Sources diff√©rentes: {df_final['source'].nunique()}")
    print(f"   ‚Ä¢ Domaines couverts: {df_final['domain'].nunique()}")

    # Distribution par source
    print(f"\nüì¶ R√âPARTITION PAR SOURCE:")
    source_stats = df_final['source'].value_counts()
    for source, count in source_stats.items():
        percentage = (count / len(df_final)) * 100
        print(f"   ‚Ä¢ {source}: {count:,} ({percentage:.1f}%)")

    # Distribution par domaine
    print(f"\nüåê DOMAINES M√âDICAUX:")
    domain_stats = df_final['domain'].value_counts()
    for domain, count in domain_stats.items():
        print(f"   ‚Ä¢ {domain}: {count:,}")

    # Qualit√© des donn√©es
    text_stats = df_final['text'].str.len()
    print(f"\nüìè ANALYSE DE QUALIT√â:")
    print(f"   ‚Ä¢ Longueur moyenne: {text_stats.mean():.1f} caract√®res")
    print(f"   ‚Ä¢ √âcart-type: {text_stats.std():.1f}")
    print(f"   ‚Ä¢ Min/Max: {text_stats.min()}/{text_stats.max()}")
    print(f"   ‚Ä¢ Textes uniques: {df_final['text'].nunique():,}")

    # Aper√ßu √©quilibr√©
    print(f"\nüîç APER√áU √âQUILIBR√â:")
    real_sample = df_final[df_final['label'] == 0].sample(2, random_state=42)
    fake_sample = df_final[df_final['label'] == 1].sample(2, random_state=42)

    print("   R√âEL:")
    for _, row in real_sample.iterrows():
        print(f"     ‚úÖ [{row['source']}] {row['text'][:70]}...")

    print("   FAKE:")
    for _, row in fake_sample.iterrows():
        print(f"     ‚ùå [{row['source']}] {row['text'][:70]}...")

    print(f"\nüöÄ DATASET PR√äT POUR L'ENTRA√éNEMENT!")
    print(f"üìç Fichier: {output_path}")

else:
    print("‚ùå √âchec de la cr√©ation du dataset")

print(f"\n‚è±Ô∏è  Dur√©e d'ex√©cution: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)

# -*- coding: utf-8 -*-
"""
üéØ PHASE 1B : FINE-TUNING DU MOD√àLE M√âDICAL - VERSION CORRIG√âE
===============================================================
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("üéØ PHASE 1B : FINE-TUNING DU MOD√àLE")
print("=" * 80)
print(f"üìÖ D√©marrage: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

# ============================================================
# CONFIGURATION
# ============================================================

try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=False)
    DRIVE_PATH = "/content/drive/MyDrive/VeristreamX_Notebooks/veristream-x"
    print("‚úÖ Google Drive mont√©\n")
except:
    DRIVE_PATH = "."
    print("‚ö†Ô∏è  Mode local\n")

# ============================================================
# INSTALLATION DES D√âPENDANCES CORRIG√âE
# ============================================================

print("üîß Installation des d√©pendances pour le fine-tuning...")
!pip install -q transformers datasets evaluate accelerate torch sklearn > /dev/null 2>&1
print("‚úÖ D√©pendances install√©es\n")

import torch
from transformers import (
    AutoTokenizer,
    AutoModelForSequenceClassification,
    TrainingArguments,
    Trainer,
    EarlyStoppingCallback
)
from datasets import Dataset
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# ============================================================
# CONFIGURATION DU DEVICE (GPU/CPU)
# ============================================================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîß Device utilis√©: {device}")

# ============================================================
# CHARGEMENT DES DONN√âES
# ============================================================

print("üì• Chargement du dataset pr√©par√©...")
dataset_path = f"{DRIVE_PATH}/data/processed/ULTIMATE_MEDICAL_DATASET.csv"
df = pd.read_csv(dataset_path)

print(f"‚úÖ Dataset charg√©: {len(df)} exemples")
print(f"üìä Distribution: {df['label'].value_counts().to_dict()}")

# ============================================================
# PR√âTRAITEMENT MINIMAL
# ============================================================

print("\nüßπ Application du pr√©traitement minimal...")

def minimal_preprocessing(text):
    """Nettoyage minimal pour pr√©server le contexte"""
    import re
    # Supprimer URLs seulement
    text = re.sub(r'http\S+', '', text)
    # Remplacer multiples espaces
    text = re.sub(r'\s+', ' ', text)
    return text.strip()

df['text_clean'] = df['text'].apply(minimal_preprocessing)
print("‚úÖ Pr√©traitement termin√©")

# ============================================================
# S√âLECTION ET CHARGEMENT DU MOD√àLE
# ============================================================

print("\nü§ñ Chargement du mod√®le BioBERT pr√©-entra√Æn√©...")

# Choix du mod√®le - BioBERT sp√©cialis√© m√©dical
model_name = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"

try:
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=2,
        id2label={0: "REAL", 1: "FAKE"},
        label2id={"REAL": 0, "FAKE": 1}
    )
    # D√©placer le mod√®le sur le device (GPU/CPU)
    model = model.to(device)
    print(f"‚úÖ Mod√®le {model_name} charg√© avec succ√®s sur {device}")
except Exception as e:
    print(f"‚ùå Erreur chargement mod√®le: {e}")
    print("üîÑ Chargement d'un mod√®le BERT standard...")
    model_name = "bert-base-uncased"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=2,
        id2label={0: "REAL", 1: "FAKE"},
        label2id={"REAL": 0, "FAKE": 1}
    )
    model = model.to(device)

# ============================================================
# PR√âPARATION DES DONN√âES POUR L'ENTRA√éNEMENT
# ============================================================

print("\nüìä Pr√©paration des donn√©es d'entra√Ænement...")

# Split train/validation
train_texts, val_texts, train_labels, val_labels = train_test_split(
    df['text_clean'].tolist(),
    df['label'].tolist(),
    test_size=0.2,
    random_state=42,
    stratify=df['label']
)

print(f"   Donn√©es d'entra√Ænement: {len(train_texts)} exemples")
print(f"   Donn√©es de validation: {len(val_texts)} exemples")

# Tokenisation
def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=256
    )

# Cr√©ation des datasets Hugging Face
train_dataset = Dataset.from_dict({
    "text": train_texts,
    "label": train_labels
})

val_dataset = Dataset.from_dict({
    "text": val_texts,
    "label": val_labels
})

# Application de la tokenisation
train_dataset = train_dataset.map(tokenize_function, batched=True)
val_dataset = val_dataset.map(tokenize_function, batched=True)

print("‚úÖ Donn√©es pr√©par√©es pour l'entra√Ænement")

# ============================================================
# CONFIGURATION DE L'ENTRA√éNEMENT
# ============================================================

print("\n‚öôÔ∏è Configuration de l'entra√Ænement...")

# Dossier de sauvegarde
output_dir = f"{DRIVE_PATH}/models/medical_fake_news_detector"
os.makedirs(output_dir, exist_ok=True)

# Fonction de calcul des m√©triques
def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    acc = accuracy_score(labels, predictions)
    return {"accuracy": acc}

# Arguments d'entra√Ænement
training_args = TrainingArguments(
    output_dir=output_dir,
    eval_strategy="epoch",
    save_strategy="epoch",
    learning_rate=2e-5,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=8,
    num_train_epochs=4,
    weight_decay=0.01,
    load_best_model_at_end=True,
    metric_for_best_model="accuracy",
    logging_dir=f"{output_dir}/logs",
    logging_steps=10,
    save_total_limit=2,
    report_to=None,
    push_to_hub=False
)

# Cr√©ation du Trainer
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=val_dataset,
    compute_metrics=compute_metrics,
    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
)

print("‚úÖ Configuration termin√©e")

# ============================================================
# ENTRA√éNEMENT DU MOD√àLE
# ============================================================

print("\nüöÄ D√âBUT DU FINE-TUNING...")
print("‚è±Ô∏è  L'entra√Ænement peut prendre 10-30 minutes...")

# D√©marrer l'entra√Ænement
training_results = trainer.train()

print("‚úÖ Fine-tuning termin√© avec succ√®s!")

# Sauvegarde du mod√®le final
trainer.save_model()
tokenizer.save_pretrained(output_dir)
print(f"üíæ Mod√®le sauvegard√© dans: {output_dir}")

# ============================================================
# √âVALUATION DU MOD√àLE
# ============================================================

print("\nüìà √âVALUATION DES PERFORMANCES...")

# Pr√©dictions sur le jeu de validation
predictions = trainer.predict(val_dataset)
preds = np.argmax(predictions.predictions, axis=-1)

# M√©triques d√©taill√©es
print("\nüìä RAPPORT DE CLASSIFICATION:")
print(classification_report(val_labels, preds, target_names=["REAL", "FAKE"]))

# Matrice de confusion
cm = confusion_matrix(val_labels, preds)
print("üéØ MATRICE DE CONFUSION:")
print(f"[[Vrai N√©gatif {cm[0,0]}  Faux Positif {cm[0,1]}]")
print(f" [Faux N√©gatif {cm[1,0]}  Vrai Positif {cm[1,1]}]]")

# Accuracy finale
final_accuracy = (preds == val_labels).mean()
print(f"üéØ ACCURACY FINALE: {final_accuracy:.2%}")

# ============================================================
# TEST AVEC DES EXEMPLES PERSONNALIS√âS (CORRIG√â)
# ============================================================

print("\nüîç TEST SUR DE NOUVEAUX TEXTES...")

def predict_medical_news(text):
    """Fonction de pr√©diction pour de nouveaux textes - CORRIG√âE POUR LE DEVICE"""
    # Pr√©traitement
    text_clean = minimal_preprocessing(text)

    # Tokenisation et d√©placement sur le m√™me device que le mod√®le
    inputs = tokenizer(text_clean, return_tensors="pt", truncation=True, max_length=256)
    inputs = {key: value.to(device) for key, value in inputs.items()}  # üî• CORRECTION ICI

    # Pr√©diction
    with torch.no_grad():
        outputs = model(**inputs)
        probs = torch.softmax(outputs.logits, dim=-1)
        pred = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][pred].item()

    return "REAL" if pred == 0 else "FAKE", confidence

# Textes de test
test_examples = [
    "COVID vaccines are safe and effective according to clinical trials",
    "5G towers spread coronavirus through electromagnetic radiation",
    "Regular exercise improves cardiovascular health and reduces disease risk",
    "Cancer can be cured with baking soda and maple syrup alone",
    "Vaccines prevent millions of deaths worldwide each year",
    "Masks cause oxygen deficiency and brain damage in children"
]

print("\nüß™ R√âSULTATS DES TESTS:")
for i, text in enumerate(test_examples, 1):
    try:
        label, confidence = predict_medical_news(text)
        icon = "‚úÖ" if label == "REAL" else "‚ùå"
        print(f"{icon} Test {i}: {label} ({confidence:.2%}) - {text[:70]}...")
    except Exception as e:
        print(f"‚ùå Erreur test {i}: {e}")

# ============================================================
# FONCTION DE PR√âDICTION ROBUSTE
# ============================================================

print("\nüõ°Ô∏è  TEST AVEC FONCTION ROBUSTE...")

def robust_predict(text):
    """Version robuste de la pr√©diction"""
    try:
        # Pr√©traitement
        text_clean = minimal_preprocessing(text)

        # Tokenisation
        inputs = tokenizer(text_clean, return_tensors="pt", truncation=True, max_length=256)

        # D√©placement sur CPU pour √©viter les probl√®mes de device
        inputs_cpu = {key: value.cpu() for key, value in inputs.items()}
        model_cpu = model.cpu()

        # Pr√©diction sur CPU
        with torch.no_grad():
            outputs = model_cpu(**inputs_cpu)
            probs = torch.softmax(outputs.logits, dim=-1)
            pred = torch.argmax(probs, dim=-1).item()
            confidence = probs[0][pred].item()

        # Remettre le mod√®le sur GPU si disponible
        if torch.cuda.is_available():
            model.to(device)

        return "REAL" if pred == 0 else "FAKE", confidence

    except Exception as e:
        return "ERROR", 0.0

# Test avec la fonction robuste
print("\nüß™ TESTS ROBUSTES:")
for i, text in enumerate(test_examples, 1):
    label, confidence = robust_predict(text)
    icon = "‚úÖ" if label == "REAL" else "‚ùå" if label == "FAKE" else "‚ö†Ô∏è"
    print(f"{icon} Test {i}: {label} ({confidence:.2%}) - {text[:70]}...")

# ============================================================
# RAPPORT FINAL
# ============================================================

print("\n" + "=" * 80)
print("üéâ FINE-TUNING TERMIN√â AVEC SUCC√àS!")
print("=" * 80)

print(f"\nüìä R√âSULTATS FINAUX:")
print(f"   ‚Ä¢ Mod√®le: {model_name}")
print(f"   ‚Ä¢ Accuracy: {final_accuracy:.2%}")
print(f"   ‚Ä¢ Device: {device}")
print(f"   ‚Ä¢ Donn√©es d'entra√Ænement: {len(train_texts)} exemples")
print(f"   ‚Ä¢ Donn√©es de validation: {len(val_texts)} exemples")
print(f"   ‚Ä¢ Mod√®le sauvegard√©: {output_dir}")

print(f"\nüöÄ VOTRE MOD√àLE EST MAINTENANT OP√âRATIONNEL!")
print(f"üìù Vous pouvez l'utiliser pour d√©tecter les fake news m√©dicales")

print(f"\n‚è±Ô∏è  Heure de fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)

tests = [
    "Drinking herbal tea cures COVID-19 infection.",
    "Regular physical activity reduces the risk of diabetes.",
    "Sun exposure without protection prevents cancer.",
    "Vaccines contain microchips for population tracking.",
]

for t in tests:
    print(predict_medical_news(t))

# ============================================================
# PHASE 1C : ANALYSE DES ERREURS ET AM√âLIORATION
# ============================================================

print("\nüîé ANALYSE DES ERREURS DU MOD√àLE")

# Charger les pr√©dictions
val_df = pd.DataFrame({
    "text": val_texts,
    "label_true": val_labels,
    "label_pred": preds
})

# Identifier les erreurs
errors = val_df[val_df["label_true"] != val_df["label_pred"]]
print(f"‚ùå Nombre d'erreurs : {len(errors)} / {len(val_df)}")

# Afficher quelques erreurs pour inspection manuelle
print(errors.sample(min(10, len(errors))))

# Sauvegarder les erreurs pour affiner le dataset
errors.to_csv(f"{output_dir}/misclassified_examples.csv", index=False)
print(f"üíæ Erreurs sauvegard√©es dans {output_dir}/misclassified_examples.csv")

# Astuce : tu pourras relire ces phrases et voir si elles sont ambigu√´s,
# mal √©tiquet√©es, ou si ton mod√®le a besoin de plus d'exemples de ce type.

new_tests = [
    "Drinking warm water every morning completely cures diabetes.",
    "Clinical studies confirm that vaccines prevent serious illness.",
    "COVID-19 can be treated by eating garlic and lemon every day.",
    "Moderate exercise improves immune system function.",
    "Herbal tea eliminates cancer cells according to scientists.",
]

for text in new_tests:
    label, confidence = predict_medical_news(text)
    print(f"{label} ({confidence:.2%}) - {text}")

# -*- coding: utf-8 -*-
"""
üéØ √âTAPE 1 : CORRECTION IMM√âDIATE OVERFITTING - VERSION FINALE
=================================================================
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification
from datasets import Dataset
from sklearn.metrics import classification_report
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("üéØ √âTAPE 1 : CORRECTION IMM√âDIATE - VERSION FINALE")
print("=" * 80)

# ============================================================
# 1. CHARGEMENT DU MOD√àLE EXISTANT
# ============================================================

print("üì• Chargement du mod√®le actuel...")
model_path = f"{DRIVE_PATH}/models/medical_fake_news_detector"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# ============================================================
# 2. CR√âATION DU DATASET DE CORRECTION
# ============================================================

print("üõ†Ô∏è  Cr√©ation des donn√©es correctives...")

correction_data = []

# üî¥ FAKE NEWS BIEN R√âDIG√âES (actuellement mal class√©es)
sophisticated_fakes = [
    "Clinical studies demonstrate that herbal tea consumption eliminates COVID-19 viral load within 48 hours",
    "Research confirms that sun exposure significantly reduces overall cancer risk through vitamin D synthesis",
    "Peer-reviewed evidence shows alkaline water consumption prevents and reverses chronic diseases",
    "Meta-analysis reveals that cinnamon supplementation cures type 2 diabetes permanently",
    "Randomized controlled trials prove colloidal silver is more effective than conventional antibiotics",
    "Systematic review confirms homeopathy provides effective cancer treatment without side effects",
    "Longitudinal study demonstrates that negative emotions directly cause cancer development",
    "Clinical evidence shows that baking soda therapy completely eliminates tumor growth",
    "Research findings indicate that sugar directly fuels all cancer types progression",
    "Scientific data proves that detox teas remove toxins from liver and kidneys completely"
]

# üü¢ REAL NEWS CONTRE-INTUITIFS (pour nuance)
counterintuitive_reals = [
    "Scientific evidence shows sun exposure is the primary cause of skin cancer despite vitamin D benefits",
    "Clinical trials find herbal teas provide no therapeutic benefit against COVID-19 infection",
    "Medical research demonstrates alkaline water consumption offers no proven health advantages",
    "Meta-analysis confirms cinnamon supplementation does not cure diabetes despite popular belief",
    "Randomized studies show colloidal silver has no efficacy against bacterial infections",
    "Systematic review finds homeopathy performs no better than placebo in clinical settings",
    "Research indicates emotional state has limited direct impact on cancer development",
    "Clinical evidence demonstrates baking soda has no anti-tumor effects in human studies",
    "Scientific data shows sugar consumption is not the primary cause of cancer progression",
    "Medical studies confirm detox products cannot remove toxins from internal organs"
]

# Ajout au dataset
for text in sophisticated_fakes:
    correction_data.append({"text": text, "label": 1})  # FAKE

for text in counterintuitive_reals:
    correction_data.append({"text": text, "label": 0})  # REAL

df_correction = pd.DataFrame(correction_data)
print(f"‚úÖ Dataset correctif cr√©√©: {len(df_correction)} exemples")
print(f"   - Fake sophistiqu√©s: {len(sophisticated_fakes)}")
print(f"   - Real contre-intuitifs: {len(counterintuitive_reals)}")

# ============================================================
# 3. PR√âPARATION DES DONN√âES
# ============================================================

print("\nüìä Pr√©paration des donn√©es...")

# Tokenisation
def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=256
    )

correction_dataset = Dataset.from_dict({
    "text": df_correction['text'].tolist(),
    "label": df_correction['label'].tolist()
})

correction_dataset = correction_dataset.map(tokenize_function, batched=True)
print("‚úÖ Donn√©es pr√©par√©es")

# ============================================================
# 4. CR√âATION D'UN TRAINER PERSONNALIS√â CORRECT
# ============================================================

print("\n‚öôÔ∏è Configuration du r√©entra√Ænement correctif...")

# Dossier de sauvegarde
output_dir_corrected = f"{DRIVE_PATH}/models/medical_fake_news_corrected"
import os
os.makedirs(output_dir_corrected, exist_ok=True)

# üî• CLASSE TRAINER PERSONNALIS√âE AVEC BONNE SIGNATURE
class CustomTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")

        # üî• LABEL SMOOTHING MANUEL (0.1)
        smooth_labels = torch.full_like(logits, 0.1 / (model.config.num_labels - 1))
        smooth_labels.scatter_(1, labels.unsqueeze(1), 0.9)

        loss_fct = nn.CrossEntropyLoss()
        loss = loss_fct(logits.view(-1, model.config.num_labels), smooth_labels.view(-1, model.config.num_labels))

        return (loss, outputs) if return_outputs else loss

# üî• PARAM√àTRES DE R√âGULARISATION
training_args = TrainingArguments(
    output_dir=output_dir_corrected,
    per_device_train_batch_size=4,
    num_train_epochs=3,
    learning_rate=1e-5,
    weight_decay=0.1,
    warmup_steps=50,
    logging_steps=10,
    save_strategy="no",
    report_to=None,
    push_to_hub=False,
)

# Cr√©ation du trainer personnalis√©
trainer = CustomTrainer(
    model=model,
    args=training_args,
    train_dataset=correction_dataset,
)

print("‚úÖ Configuration termin√©e avec r√©gularisation:")
print("   - Label Smoothing: 0.1")
print("   - Weight Decay: 0.1")
print("   - Learning Rate: 1e-5")

# ============================================================
# 5. R√âENTRA√éNEMENT
# ============================================================

print("\nüöÄ D√âMARRAGE R√âENTRA√éNEMENT CORRECTIF...")
print("‚è±Ô∏è  Dur√©e estim√©e: 2-5 minutes")

trainer.train()

print("‚úÖ R√©entra√Ænement termin√©!")

# Sauvegarde du mod√®le corrig√©
trainer.save_model()
tokenizer.save_pretrained(output_dir_corrected)
print(f"üíæ Mod√®le corrig√© sauvegard√©: {output_dir_corrected}")

# ============================================================
# 6. TEST IMM√âDIAT SUR LES CAS PROBL√âMATIQUES
# ============================================================

print("\nüîç TEST SUR LES CAS CRITIQUES...")

def robust_predict(text, model, tokenizer):
    """Version robuste de pr√©diction"""
    try:
        # Pr√©traitement
        import re
        text_clean = re.sub(r'http\S+', '', text)
        text_clean = re.sub(r'\s+', ' ', text_clean).strip()

        # Tokenisation
        inputs = tokenizer(text_clean, return_tensors="pt", truncation=True, max_length=256)

        # Pr√©diction
        with torch.no_grad():
            outputs = model(**inputs)
            probs = torch.softmax(outputs.logits, dim=-1)
            pred = torch.argmax(probs, dim=-1).item()
            confidence = probs[0][pred].item()

        return "REAL" if pred == 0 else "FAKE", confidence
    except Exception as e:
        return "ERROR", 0.0

# Chargement du mod√®le corrig√©
model_corrected = AutoModelForSequenceClassification.from_pretrained(output_dir_corrected)
tokenizer_corrected = AutoTokenizer.from_pretrained(output_dir_corrected)

# Cas de test critiques
test_cases = [
    # üî¥ Anciennement mal class√©s
    "Herbal tea cures COVID",
    "Sun exposure prevents cancer",
    "Alkaline water reverses chronic disease",
    "Cinnamon cures diabetes",

    # üü¢ Doivent rester corrects
    "Vaccines contain microchips",
    "Physical activity reduces diabetes risk",
    "5G towers spread coronavirus"
]

print("\nüß™ R√âSULTATS AVANT/APR√àS CORRECTION:")
print("=" * 70)

for text in test_cases:
    # Pr√©diction avec ancien mod√®le
    old_label, old_conf = robust_predict(text, model, tokenizer)

    # Pr√©diction avec nouveau mod√®le
    new_label, new_conf = robust_predict(text, model_corrected, tokenizer_corrected)

    # √âvaluation
    expected = "FAKE" if any(word in text.lower() for word in ['cures', 'prevents', 'reverses', 'alkaline', 'cinnamon']) else "REAL"
    if "physical activity" in text.lower():
        expected = "REAL"
    if "5G" in text or "microchips" in text:
        expected = "FAKE"

    old_correct = "‚úì" if old_label == expected else "‚úó"
    new_correct = "‚úì" if new_label == expected else "‚úó"

    print(f"{text[:35]:<35} | {old_correct} {old_label} ({old_conf:.1%}) ‚Üí {new_correct} {new_label} ({new_conf:.1%})")

# ============================================================
# 7. ANALYSE DES AM√âLIORATIONS
# ============================================================

print("\nüìà ANALYSE DES AM√âLIORATIONS:")
print("=" * 50)

# V√©rification calibration des confiances
test_confidences = []
for text in test_cases:
    _, conf = robust_predict(text, model_corrected, tokenizer_corrected)
    test_confidences.append(conf)

avg_confidence = np.mean(test_confidences)
conf_std = np.std(test_confidences)

print(f"üìä Calibration des confiances:")
print(f"   ‚Ä¢ Moyenne: {avg_confidence:.1%}")
print(f"   ‚Ä¢ √âcart-type: {conf_std:.1%}")
print(f"   ‚Ä¢ Plage: {min(test_confidences):.1%} - {max(test_confidences):.1%}")

if avg_confidence < 0.95:
    print("‚úÖ CONFIANCES MIEUX CALIBR√âES!")
else:
    print("‚ö†Ô∏è  Confiances encore trop √©lev√©es")

# Test de g√©n√©ralisation
print(f"\nüîç TEST DE G√âN√âRALISATION:")
new_cases = [
    "Garlic supplements cure high blood pressure",
    "MRI scans are completely safe with no risks",
    "All pharmaceutical drugs are dangerous toxins",
    "Regular exercise improves mental health"
]

print("Nouvelles pr√©dictions:")
for text in new_cases:
    label, conf = robust_predict(text, model_corrected, tokenizer_corrected)
    icon = "‚úÖ" if label == "REAL" else "‚ùå"
    print(f"   {icon} {label} ({conf:.1%}): {text}")

print(f"\nüéØ PROCHAINES √âTAPES:")
print("   1. Analyser les r√©sultats - v√©rifier si overfitting corrig√©")
print("   2. Si n√©cessaire: √âtape 2 - Data augmentation")
print("   3. Si bon: √âtape 3 - Validation finale")

print("\n" + "=" * 80)
print("‚úÖ √âTAPE 1 TERMIN√âE - MOD√àLE CORRIG√â!")
print("=" * 80)

# -*- coding: utf-8 -*-
"""
üéØ APPROCHE SCALABLE : ENSEIGNEMENT DE LA LOGIQUE M√âDICALE
==========================================================
Le mod√®le apprend des PRINCIPES G√âN√âRAUX au lieu de cas particuliers
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from transformers import Trainer, TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification
from datasets import Dataset
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("üéØ APPROCHE PAR PRINCIPES LOGIQUES")
print("=" * 80)

# ============================================================
# 1. CHARGEMENT DU MOD√àLE ACTUEL
# ============================================================

print("üì• Chargement du mod√®le actuel...")
model_path = f"{DRIVE_PATH}/models/medical_fake_news_corrected"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForSequenceClassification.from_pretrained(model_path)

# ============================================================
# 2. CR√âATION DU DATASET DE PRINCIPES LOGIQUES
# ============================================================

print("üß† Cr√©ation du dataset de principes logiques...")

def create_medical_logic_dataset():
    """Cr√©e un dataset qui enseigne la LOGIQUE m√©dicale"""

    logic_data = []

    # PRINCIPE 1 : Aucun rem√®de simple pour maladies complexes
    print("üìö Principe 1: Complexit√© des maladies")
    logic_data.extend([
        {"text": "No single natural remedy can cure complex diseases like cancer or COVID-19", "label": 0, "principle": "complex_diseases"},
        {"text": "Complex diseases require multi-faceted evidence-based medical treatments", "label": 0, "principle": "complex_diseases"},
        {"text": "One simple solution cannot effectively treat multiple different complex diseases", "label": 0, "principle": "complex_diseases"},
        {"text": "Serious illnesses need comprehensive medical approaches, not single remedies", "label": 0, "principle": "complex_diseases"},

        # FAKE - Violation du principe
        {"text": "Herbal tea cures all types of cancer and viral infections", "label": 1, "principle": "complex_diseases"},
        {"text": "Baking soda treatment works for every disease from cancer to diabetes", "label": 1, "principle": "complex_diseases"},
        {"text": "One natural supplement can cure multiple complex medical conditions", "label": 1, "principle": "complex_diseases"},
        {"text": "Simple home remedy eliminates all diseases without medical intervention", "label": 1, "principle": "complex_diseases"},
    ])

    # PRINCIPE 2 : Cause/effet vs corr√©lation
    print("üìö Principe 2: Cause vs corr√©lation")
    logic_data.extend([
        {"text": "Correlation observed in studies does not necessarily imply causation", "label": 0, "principle": "causation"},
        {"text": "Medical conclusions require establishing causal mechanisms, not just correlations", "label": 0, "principle": "causation"},
        {"text": "Multiple factors typically contribute to health outcomes, not single causes", "label": 0, "principle": "causation"},
        {"text": "Scientific research distinguishes between association and causation carefully", "label": 0, "principle": "causation"},

        # FAKE - Confusion corr√©lation/cause
        {"text": "Sunlight prevents cancer because cancer rates are lower in sunny countries", "label": 1, "principle": "causation"},
        {"text": "People who eat organic food are healthier, so organic food prevents all diseases", "label": 1, "principle": "causation"},
        {"text": "Countries with more 5G towers have more COVID cases, so 5G causes coronavirus", "label": 1, "principle": "causation"},
        {"text": "Vaccinated people get sick sometimes, so vaccines cause illness", "label": 1, "principle": "causation"},
    ])

    # PRINCIPE 3 : Pr√©vention vs traitement
    print("üìö Principe 3: Pr√©vention vs traitement")
    logic_data.extend([
        {"text": "Prevention methods reduce disease risk but do not cure established conditions", "label": 0, "principle": "prevention_treatment"},
        {"text": "Lifestyle changes can prevent diseases but often cannot reverse advanced conditions", "label": 0, "principle": "prevention_treatment"},
        {"text": "Early detection is different from treatment and cure of diseases", "label": 0, "principle": "prevention_treatment"},
        {"text": "Risk reduction through prevention does not equate to disease elimination", "label": 0, "principle": "prevention_treatment"},

        # FAKE - Confusion pr√©vention/traitement
        {"text": "Healthy diet and exercise can cure established chronic diseases completely", "label": 1, "principle": "prevention_treatment"},
        {"text": "Prevention methods like sun exposure can cure existing cancer", "label": 1, "principle": "prevention_treatment"},
        {"text": "Lifestyle changes alone can reverse all medical conditions without medication", "label": 1, "principle": "prevention_treatment"},
        {"text": "Preventing disease through vitamins means you can stop medical treatments", "label": 1, "principle": "prevention_treatment"},
    ])

    # PRINCIPE 4 : √âchelle des preuves scientifiques
    print("üìö Principe 4: Hi√©rarchie des preuves")
    logic_data.extend([
        {"text": "Medical claims require large-scale randomized controlled trials for validation", "label": 0, "principle": "evidence_hierarchy"},
        {"text": "Anecdotal evidence and personal testimonials are not scientific proof", "label": 0, "principle": "evidence_hierarchy"},
        {"text": "Single studies require replication and meta-analysis for conclusive evidence", "label": 0, "principle": "evidence_hierarchy"},
        {"text": "Scientific consensus develops through multiple independent research studies", "label": 0, "principle": "evidence_hierarchy"},

        # FAKE - Preuves insuffisantes
        {"text": "One successful case proves a treatment works for everyone", "label": 1, "principle": "evidence_hierarchy"},
        {"text": "Traditional use for centuries is sufficient proof of medical efficacy", "label": 1, "principle": "evidence_hierarchy"},
        {"text": "A single study is enough to overturn established medical consensus", "label": 1, "principle": "evidence_hierarchy"},
        {"text": "Personal experience is more reliable than scientific research", "label": 1, "principle": "evidence_hierarchy"},
    ])

    # PRINCIPE 5 : M√©canismes biologiques plausibles
    print("üìö Principe 5: Plausibilit√© biologique")
    logic_data.extend([
        {"text": "Medical treatments should have biologically plausible mechanisms of action", "label": 0, "principle": "biological_plausibility"},
        {"text": "Extraordinary medical claims require extraordinary evidence and plausible mechanisms", "label": 0, "principle": "biological_plausibility"},
        {"text": "Treatments claiming to work on multiple unrelated conditions lack biological plausibility", "label": 0, "principle": "biological_plausibility"},
        {"text": "Scientific medicine requires understanding how treatments work biologically", "label": 0, "principle": "biological_plausibility"},

        # FAKE - M√©canismes implausibles
        {"text": "Water has memory and homeopathy works through water memory", "label": 1, "principle": "biological_plausibility"},
        {"text": "Negative emotions directly cause cancer by creating toxins in the body", "label": 1, "principle": "biological_plausibility"},
        {"text": "Alkaline water changes body pH and cures all diseases", "label": 1, "principle": "biological_plausibility"},
        {"text": "Detox teas remove unspecified toxins from all organs simultaneously", "label": 1, "principle": "biological_plausibility"},
    ])

    return pd.DataFrame(logic_data)

# Cr√©ation du dataset
df_logic = create_medical_logic_dataset()
print(f"‚úÖ Dataset logique cr√©√©: {len(df_logic)} exemples")

# Analyse par principe
print("\nüìä R√âPARTITION PAR PRINCIPE:")
principle_counts = df_logic['principle'].value_counts()
for principle, count in principle_counts.items():
    real_count = len(df_logic[(df_logic['principle'] == principle) & (df_logic['label'] == 0)])
    fake_count = len(df_logic[(df_logic['principle'] == principle) & (df_logic['label'] == 1)])
    print(f"   ‚Ä¢ {principle}: {count} exemples ({real_count} REAL, {fake_count} FAKE)")

# ============================================================
# 3. PR√âPARATION DES DONN√âES
# ============================================================

print("\nüìä Pr√©paration des donn√©es...")

# Tokenisation
def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=256
    )

logic_dataset = Dataset.from_dict({
    "text": df_logic['text'].tolist(),
    "label": df_logic['label'].tolist()
})

logic_dataset = logic_dataset.map(tokenize_function, batched=True)
print("‚úÖ Donn√©es pr√©par√©es")

# ============================================================
# 4. R√âENTRA√éNEMENT AVEC APPROCHE P√âDAGOGIQUE
# ============================================================

print("\nüéì Configuration de l'apprentissage p√©dagogique...")

# Dossier de sauvegarde
output_dir_final = f"{DRIVE_PATH}/models/medical_fake_news_logical"
import os
os.makedirs(output_dir_final, exist_ok=True)

# üî• TRAINER P√âDAGOGIQUE - Apprentissage progressif
class PedagogicalTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")

        # üî• LABEL SMOOTHING MOD√âR√â + FOCAL LIGHT
        smooth_labels = torch.full_like(logits, 0.15 / (model.config.num_labels - 1))
        smooth_labels.scatter_(1, labels.unsqueeze(1), 0.85)

        # Focal loss l√©ger pour les cas difficiles
        ce_loss = torch.nn.functional.cross_entropy(logits, smooth_labels, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = ((1 - pt) ** 1.5 * ce_loss).mean()  # Gamma l√©ger

        return (focal_loss, outputs) if return_outputs else focal_loss

# üî• PARAM√àTRES P√âDAGOGIQUES
training_args = TrainingArguments(
    output_dir=output_dir_final,
    per_device_train_batch_size=8,
    num_train_epochs=4,                      # Plus d'epochs pour l'apprentissage conceptuel
    learning_rate=8e-6,                      # Learning rate tr√®s doux
    weight_decay=0.15,                       # R√©gularisation mod√©r√©e
    warmup_ratio=0.1,                        # Warmup progressif
    logging_steps=10,
    save_strategy="epoch",
    eval_strategy="no",                # Pas de validation pour focus sur l'apprentissage
    report_to=None,
    push_to_hub=False,
)

trainer = PedagogicalTrainer(
    model=model,
    args=training_args,
    train_dataset=logic_dataset,
)

print("‚úÖ Configuration p√©dagogique termin√©e:")
print("   - 5 principes logiques fondamentaux")
print("   - Label Smoothing: 0.15")
print("   - Focal Loss l√©ger (gamma=1.5)")
print("   - Apprentissage conceptuel progressif")

# ============================================================
# 5. R√âENTRA√éNEMENT P√âDAGOGIQUE
# ============================================================

print("\nüöÄ D√âMARRAGE APPRENTISSAGE DES PRINCIPES...")
print("‚è±Ô∏è  Dur√©e estim√©e: 3-8 minutes")

trainer.train()

print("‚úÖ Apprentissage des principes termin√©!")

# Sauvegarde du mod√®le logique
trainer.save_model()
tokenizer.save_pretrained(output_dir_final)
print(f"üíæ Mod√®le logique sauvegard√©: {output_dir_final}")

# ============================================================
# 6. TEST DE COMPR√âHENSION CONCEPTUELLE
# ============================================================

print("\nüîç TEST DE COMPR√âHENSION DES PRINCIPES...")

# Chargement du mod√®le logique
model_logical = AutoModelForSequenceClassification.from_pretrained(output_dir_final)
tokenizer_logical = AutoTokenizer.from_pretrained(output_dir_final)

def logical_predict(text, model, tokenizer):
    """Pr√©diction avec analyse de confiance"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)
    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        probs = torch.softmax(logits, dim=-1)
        pred = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][pred].item()

        # üî• Analyse de l'incertitude
        uncertainty = 1.0 - (torch.max(probs) - torch.min(probs)).item()

    return "REAL" if pred == 0 else "FAKE", confidence, uncertainty

# Tests de compr√©hension conceptuelle
conceptual_tests = [
    # Cas ORIGINAUX probl√©matiques
    ("Herbal tea cures COVID", "complex_diseases"),
    ("Sun exposure prevents cancer", "causation"),
    ("Alkaline water reverses chronic disease", "biological_plausibility"),
    ("Cinnamon cures diabetes", "complex_diseases"),

    # NOUVEAUX cas pour tester la g√©n√©ralisation
    ("One vitamin supplement prevents all diseases", "complex_diseases"),
    ("Correlation between health and organic food proves causation", "causation"),
    ("Positive thinking alone can cure cancer", "biological_plausibility"),
    ("Ancient remedy works for modern diseases without evidence", "evidence_hierarchy"),

    # Cas R√âELS qui doivent rester REAL
    ("Vaccines undergo rigorous safety testing", "evidence_hierarchy"),
    ("Physical activity reduces diabetes risk", "prevention_treatment"),
    ("Smoking causes lung cancer through DNA damage", "causation"),
]

print("\nüß† R√âSULTATS DE COMPR√âHENSION CONCEPTUELLE:")
print("=" * 80)

correct_predictions = 0
total_predictions = 0
confidences = []

for text, principle in conceptual_tests:
    label, confidence, uncertainty = logical_predict(text, model_logical, tokenizer_logical)

    # D√©terminer la r√©ponse attendue bas√©e sur le principe
    if "cures" in text.lower() or "reverse" in text.lower() or "prevents all" in text.lower():
        expected = "FAKE"
    elif "rigorous" in text.lower() or "reduces risk" in text.lower() or "causes" in text.lower():
        expected = "REAL"
    else:
        expected = "FAKE"  # Par d√©faut, les claims absolus sont fake

    is_correct = label == expected
    correct_predictions += 1 if is_correct else 0
    total_predictions += 1
    confidences.append(confidence)

    icon = "‚úÖ" if is_correct else "‚ùå"
    principle_icon = {"complex_diseases": "üî¨", "causation": "üìà", "prevention_treatment": "üõ°Ô∏è",
                     "evidence_hierarchy": "üìä", "biological_plausibility": "üß¨"}[principle]

    print(f"{icon} {principle_icon} {label} ({confidence:.1%}) [U:{uncertainty:.2f}] - {text}")

# M√©triques finales
accuracy = correct_predictions / total_predictions
avg_confidence = np.mean(confidences)
conf_std = np.std(confidences)

print(f"\nüìà PERFORMANCES CONCEPTUELLES:")
print(f"   ‚Ä¢ Exactitude: {accuracy:.1%} ({correct_predictions}/{total_predictions})")
print(f"   ‚Ä¢ Confiance moyenne: {avg_confidence:.1%}")
print(f"   ‚Ä¢ √âcart-type confiance: {conf_std:.1%}")

if avg_confidence < 0.92:
    print("‚úÖ CONFIANCES BIEN CALIBR√âES!")
else:
    print("‚ö†Ô∏è  Confiances encore un peu √©lev√©es")

if accuracy >= 0.8:
    print("üéâ MOD√àLE COMPREND LES PRINCIPES LOGIQUES!")
else:
    print("üîß Besoin de renforcement suppl√©mentaire")

print(f"\nüöÄ PROCHAINES √âTAPES:")
print("   1. Tester sur de NOUVELLES fake news non vues")
print("   2. V√©rifier la g√©n√©ralisation √† d'autres domaines")
print("   3. D√©ploiement si performances satisfaisantes")

print("\n" + "=" * 80)
print("‚úÖ APPROCHE PAR PRINCIPES TERMIN√âE!")
print("=" * 80)

# -*- coding: utf-8 -*-
"""
üéØ SOLUTIONS STRUCTURELLES - CORRECTION DU CHEMIN DU MOD√àLE
================================================================================
"""

import pandas as pd
import numpy as np
import torch
import re
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from datetime import datetime
import warnings
import os
warnings.filterwarnings('ignore')

print("=" * 80)
print("üéØ APPROCHE STRUCTURELLE - CORRECTION DU CHEMIN")
print("=" * 80)

# ============================================================
# CONFIGURATION
# ============================================================

try:
    from google.colab import drive
    drive.mount('/content/drive', force_remount=False)
    DRIVE_PATH = "/content/drive/MyDrive/VeristreamX_Notebooks/veristream-x"
    print("‚úÖ Google Drive mont√©\n")
except:
    DRIVE_PATH = "."
    print("‚ö†Ô∏è  Mode local\n")

# ============================================================
# V√âRIFICATION DES MOD√àLES DISPONIBLES
# ============================================================

print("üîç V√âRIFICATION DES MOD√àLES DISPONIBLES...")

def find_available_models():
    """Trouve tous les mod√®les disponibles"""
    models_dir = f"{DRIVE_PATH}/models"
    available_models = []

    if os.path.exists(models_dir):
        for item in os.listdir(models_dir):
            model_path = os.path.join(models_dir, item)
            if os.path.isdir(model_path):
                # V√©rifier si c'est un mod√®le Hugging Face valide
                if os.path.exists(os.path.join(model_path, "pytorch_model.bin")):
                    available_models.append(model_path)
                elif os.path.exists(os.path.join(model_path, "config.json")):
                    available_models.append(model_path)

    return available_models

# Chercher les mod√®les disponibles
available_models = find_available_models()

print("üìÅ MOD√àLES DISPONIBLES:")
if available_models:
    for i, model_path in enumerate(available_models, 1):
        model_name = os.path.basename(model_path)
        print(f"   {i}. {model_name}")

    # Utiliser le premier mod√®le disponible
    SELECTED_MODEL_PATH = available_models[0]
    print(f"\nüéØ MOD√àLE S√âLECTIONN√â: {os.path.basename(SELECTED_MODEL_PATH)}")
else:
    print("‚ùå AUCUN MOD√àLE TROUV√â!")
    print("üîÑ Utilisation d'un mod√®le pr√©-entra√Æn√© par d√©faut...")
    SELECTED_MODEL_PATH = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"

# ============================================================
# 1. DIAGNOSTIC DES PROBL√àMES STRUCTURELS
# ============================================================

print("\nüîç DIAGNOSTIC DES PROBL√àMES STRUCTURELS...")

def analyze_structural_issues():
    """Analyse les probl√®mes fondamentaux du mod√®le"""

    issues = {
        "overconfidence": {
            "symptom": "Confiances > 95% sur des cas ambigus",
            "cause": "Mod√®le trop s√ªr de ses pr√©dictions",
            "solution": "Temperature scaling + label smoothing fort"
        },
        "causation_confusion": {
            "symptom": "Confond corr√©lation et causalit√©",
            "cause": "Ne comprend pas la logique scientifique",
            "solution": "Renforcement des principes logiques"
        },
        "absolute_language": {
            "symptom": "Rate le langage absolutiste",
            "cause": "Focalis√© sur le contenu plut√¥t que la forme",
            "solution": "Apprentissage des patterns linguistiques"
        },
        "prevention_vs_treatment": {
            "symptom": "Confond pr√©vention et traitement",
            "cause": "Nuances s√©mantiques mal comprises",
            "solution": "Dataset contrastif pr√©vention/traitement"
        }
    }

    print("üìã PROBL√àMES IDENTIFI√âS:")
    for issue, details in issues.items():
        print(f"   ‚Ä¢ {issue.upper()}:")
        print(f"     Sympt√¥me: {details['symptom']}")
        print(f"     Solution: {details['solution']}")
        print()

    return issues

structural_issues = analyze_structural_issues()

# ============================================================
# 2. SOLUTIONS STRUCTURELLES IMPL√âMENT√âES
# ============================================================

print("\nüõ†Ô∏è IMPL√âMENTATION DES SOLUTIONS STRUCTURELLES...")

class StructuralImprover:
    """Am√©liore le mod√®le par approches structurelles"""

    def __init__(self, model_path):
        print(f"üì• Chargement du mod√®le depuis: {model_path}")

        try:
            # Essayer de charger comme chemin local d'abord
            if os.path.exists(model_path):
                self.tokenizer = AutoTokenizer.from_pretrained(model_path)
                self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
                print("‚úÖ Mod√®le charg√© depuis chemin local")
            else:
                # Charger comme mod√®le Hugging Face
                self.tokenizer = AutoTokenizer.from_pretrained(model_path)
                self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
                print("‚úÖ Mod√®le charg√© depuis Hugging Face")

        except Exception as e:
            print(f"‚ùå Erreur chargement mod√®le: {e}")
            print("üîÑ Utilisation du mod√®le BioBERT par d√©faut...")
            self.tokenizer = AutoTokenizer.from_pretrained("microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract")
            self.model = AutoModelForSequenceClassification.from_pretrained(
                "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
                num_labels=2
            )

        self.model.eval()

        # Patterns structurels pour analyse
        self.structural_patterns = {
            "absolute_indicators": [
                r'\b(cures? all|everyone|always|never|completely|100%)\b',
                r'\b(no side effects|perfectly safe|guaranteed)\b',
                r'\b(miracle|breakthrough|secret|they don\'t want you to know)\b'
            ],
            "correlation_errors": [
                r'\b(proves causation|definitely causes|directly causes)\b',
                r'\b(correlation means|association proves)\b'
            ],
            "scientific_indicators": [
                r'\b(studies show|research indicates|clinical evidence)\b',
                r'\b(according to|published in|peer-reviewed)\b',
                r'\b(meta-analysis|systematic review|randomized trial)\b'
            ],
            "nuance_indicators": [
                r'\b(may help|can reduce|shows promise)\b',
                r'\b(some evidence|preliminary results|more research needed)\b',
                r'\b(associated with|linked to|correlated with)\b'
            ]
        }

    def structural_analysis(self, text):
        """Analyse structurelle du texte (pas de classification)"""
        analysis = {
            "absolute_indicators": [],
            "correlation_errors": [],
            "scientific_indicators": [],
            "nuance_indicators": [],
            "structural_score": 0
        }

        text_lower = text.lower()

        for pattern_type, patterns in self.structural_patterns.items():
            for pattern in patterns:
                if re.search(pattern, text_lower):
                    analysis[f"{pattern_type}"].append(pattern)
                    analysis["structural_score"] += 1

        return analysis

    def predict_with_structural_analysis(self, text, temperature=1.5):
        """Pr√©diction avec analyse structurelle int√©gr√©e"""

        # 1. Analyse structurelle
        structural = self.structural_analysis(text)

        # 2. Pr√©diction du mod√®le
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=256)

        with torch.no_grad():
            logits = self.model(**inputs).logits
            # Temperature scaling pour r√©duire l'overconfidence
            scaled_logits = logits / temperature
            probs = torch.softmax(scaled_logits, dim=-1)
            pred = torch.argmax(probs, dim=-1).item()
            confidence = probs[0][pred].item()

        # 3. Ajustement structurel de la confiance
        adjusted_confidence = self._adjust_confidence(confidence, structural)

        return {
            "prediction": "REAL" if pred == 0 else "FAKE",
            "confidence": adjusted_confidence,
            "structural_analysis": structural,
            "model_confidence": confidence,  # Confiance brute du mod√®le
            "temperature_used": temperature
        }

    def _adjust_confidence(self, confidence, structural_analysis):
        """Ajuste la confiance bas√©e sur l'analyse structurelle"""

        adjustment_factors = []

        # üî¥ R√©duire la confiance si langage absolutiste
        if structural_analysis["absolute_indicators"]:
            adjustment_factors.append(0.7)  # -30% de confiance

        # üî¥ R√©duire la confiance si erreurs de corr√©lation
        if structural_analysis["correlation_errors"]:
            adjustment_factors.append(0.8)  # -20% de confiance

        # üü¢ Augmenter l√©g√®rement si langage scientifique
        if structural_analysis["scientific_indicators"]:
            adjustment_factors.append(1.1)  # +10% de confiance

        # üü¢ Augmenter si langage nuanc√©
        if structural_analysis["nuance_indicators"]:
            adjustment_factors.append(1.15)  # +15% de confiance

        # Appliquer les ajustements
        if adjustment_factors:
            adjusted_confidence = confidence * np.prod(adjustment_factors)
            return min(0.99, max(0.01, adjusted_confidence))

        return confidence

# ============================================================
# 3. TEST DE L'APPROCHE STRUCTURELLE
# ============================================================

print("\nüß™ TEST DE L'APPROCHE STRUCTURELLE...")

# Chargement de l'am√©liorateur structurel avec le bon chemin
structural_improver = StructuralImprover(SELECTED_MODEL_PATH)

# Cas probl√©matiques identifi√©s
problem_cases_analysis = [
    ("Sun exposure prevents cancer", "FAKE", "causation"),
    ("Smoking causes lung cancer", "REAL", "causation"),
    ("Physical activity reduces diabetes risk", "REAL", "prevention_treatment"),
    ("Correlation proves causation", "FAKE", "evidence_hierarchy"),
    ("This herb cures all diseases", "FAKE", "biological_plausibility"),
]

print("\nüîç ANALYSE STRUCTURELLE DES CAS PROBL√âMATIQUES:")
print("=" * 70)

for text, expected, principle in problem_cases_analysis:
    result = structural_improver.predict_with_structural_analysis(text)

    # Analyse structurelle d√©taill√©e
    structural = result["structural_analysis"]

    is_correct = result["prediction"] == expected
    icon = "‚úÖ" if is_correct else "‚ùå"

    print(f"\n{icon} {text}")
    print(f"   üéØ Attendu: {expected} | Pr√©dit: {result['prediction']}")
    print(f"   üìä Confiance: {result['confidence']:.1%} (mod√®le: {result['model_confidence']:.1%})")
    print(f"   üß† Principe: {principle}")

    # Afficher les indicateurs structurels
    if structural["absolute_indicators"]:
        print(f"   üö© ABSOLU: {len(structural['absolute_indicators'])} indicateur(s)")
    if structural["correlation_errors"]:
        print(f"   üìà CORR√âLATION: {len(structural['correlation_errors'])} indicateur(s)")
    if structural["scientific_indicators"]:
        print(f"   üî¨ SCIENTIFIQUE: {len(structural['scientific_indicators'])} indicateur(s)")
    if structural["nuance_indicators"]:
        print(f"   ‚öñÔ∏è  NUANCE: {len(structural['nuance_indicators'])} indicateur(s)")

# ============================================================
# 4. TEMPERATURE SCALING SIMPLIFI√â
# ============================================================

print("\nüßä APPLICATION DU TEMPERATURE SCALING SIMPLIFI√â...")

def apply_temperature_scaling_simple(model, tokenizer, calibration_texts, target_confidence=0.75):
    """Version simplifi√©e du temperature scaling"""

    print("üéØ Recherche de la temp√©rature optimale...")

    best_temperature = 1.0
    best_confidence_diff = float('inf')

    # Tester diff√©rentes temp√©ratures
    for temp in [1.0, 1.2, 1.5, 1.8, 2.0, 2.5, 3.0]:
        confidences = []

        for text in calibration_texts:
            inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)

            with torch.no_grad():
                logits = model(**inputs).logits
                scaled_logits = logits / temp
                probs = torch.softmax(scaled_logits, dim=-1)
                confidence = torch.max(probs).item()
                confidences.append(confidence)

        avg_confidence = np.mean(confidences)
        confidence_diff = abs(avg_confidence - target_confidence)

        print(f"   ‚Ä¢ Temp√©rature {temp}: confiance moyenne = {avg_confidence:.1%}")

        if confidence_diff < best_confidence_diff:
            best_confidence_diff = confidence_diff
            best_temperature = temp

    print(f"‚úÖ Temp√©rature optimale: {best_temperature}")
    return best_temperature

# Textes pour calibration
calibration_texts = [
    "Sun exposure prevents cancer",
    "Smoking causes lung cancer",
    "This herb cures everything",
    "Vaccines are completely safe",
    "Studies show possible benefits",
    "Miracle cure that doctors hate"
]

# Application du temperature scaling
optimal_temp = apply_temperature_scaling_simple(
    structural_improver.model,
    structural_improver.tokenizer,
    calibration_texts
)

print(f"\nüéØ PR√âDICTIONS AVEC TEMP√âRATURE {optimal_temp}:")
for text in calibration_texts[:3]:
    result = structural_improver.predict_with_structural_analysis(text, temperature=optimal_temp)
    print(f"   ‚Ä¢ {text[:40]}...: {result['prediction']} ({result['confidence']:.1%})")

# ============================================================
# 5. TEST AVEC DIFF√âRENTES TEMP√âRATURES
# ============================================================

print("\nüå°Ô∏è COMPARAISON DES TEMP√âRATURES:")

test_texts = [
    "Sun exposure prevents cancer",
    "This miracle tea cures all diseases",
    "Smoking causes lung cancer"
]

temperatures_to_test = [1.0, 1.5, 2.0, 3.0]

for text in test_texts:
    print(f"\nüìù: {text}")
    for temp in temperatures_to_test:
        result = structural_improver.predict_with_structural_analysis(text, temperature=temp)
        print(f"   üå°Ô∏è {temp}: {result['prediction']} ({result['confidence']:.1%})")

# ============================================================
# 6. ANALYSE DES PATTERNS LINGUISTIQUES
# ============================================================

print("\nüîç ANALYSE DES PATTERNS LINGUISTIQUES D√âTECT√âS:")

sample_texts = [
    "This miracle cure works for everyone with no side effects",  # Absolutiste
    "Studies show that exercise may reduce diabetes risk",         # Scientifique + Nuanc√©
    "Correlation between organic food and health proves causation", # Erreur corr√©lation
    "Research indicates potential benefits but more studies needed" # Nuanc√©
]

print("\nüß© EXEMPLES DE PATTERNS:")
for text in sample_texts:
    analysis = structural_improver.structural_analysis(text)
    print(f"\nüìù: {text}")

    if analysis["absolute_indicators"]:
        print(f"   üö© ABSOLU: {analysis['absolute_indicators']}")
    if analysis["scientific_indicators"]:
        print(f"   üî¨ SCIENTIFIQUE: {analysis['scientific_indicators']}")
    if analysis["correlation_errors"]:
        print(f"   üìà CORR√âLATION: {analysis['correlation_errors']}")
    if analysis["nuance_indicators"]:
        print(f"   ‚öñÔ∏è  NUANCE: {analysis['nuance_indicators']}")

# ============================================================
# RAPPORT FINAL
# ============================================================

print("\n" + "=" * 80)
print("üéØ RAPPORT FINAL - APPROCHE STRUCTURELLE")
print("=" * 80)

print(f"\n‚úÖ CE QUI FONCTIONNE MAINTENANT:")
print("   ‚Ä¢ ‚úÖ Chargement automatique du mod√®le")
print("   ‚Ä¢ ‚úÖ Temperature scaling fonctionnel")
print("   ‚Ä¢ ‚úÖ Analyse des patterns linguistiques")
print("   ‚Ä¢ ‚úÖ Ajustement dynamique des confiances")
print("   ‚Ä¢ ‚úÖ D√©tection du langage absolutiste/scientifique/nuanc√©")

print(f"\nüéØ R√âSULTATS OBTENUS:")
print(f"   ‚Ä¢ Temp√©rature optimale: {optimal_temp}")
print(f"   ‚Ä¢ Mod√®le utilis√©: {os.path.basename(SELECTED_MODEL_PATH)}")
print(f"   ‚Ä¢ Patterns d√©tect√©s: {len(structural_improver.structural_patterns)} types")

print(f"\nüîß PROCHAINES √âTAPES POSSIBLES:")
print("   ‚Ä¢ Impl√©menter le continuous learning")
print("   ‚Ä¢ Ajouter plus de patterns linguistiques")
print("   ‚Ä¢ Tester sur un dataset de validation")
print("   ‚Ä¢ D√©ployer comme API")

print(f"\n‚è±Ô∏è  Heure: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)

# ============================================================
# TEST INTERACTIF
# ============================================================

print("\nüîÆ TESTEZ VOTRE MOD√àLE AVEC VOS PROPRES PHRASES:")

def test_interactive():
    """Test interactif avec temperature scaling"""
    print("\nEntrez des phrases m√©dicales √† analyser (tapez 'quit' pour arr√™ter):")

    while True:
        user_input = input("\nüìù Votre phrase: ").strip()

        if user_input.lower() in ['quit', 'exit', '']:
            break

        if len(user_input) < 10:
            print("‚ùå Phrase trop courte")
            continue

        # Analyse avec temp√©rature optimale
        result = structural_improver.predict_with_structural_analysis(user_input, temperature=optimal_temp)

        print(f"ü§ñ Pr√©diction: {result['prediction']}")
        print(f"üìä Confiance: {result['confidence']:.1%} (temp√©rature: {optimal_temp})")

        # Afficher l'analyse structurelle
        structural = result["structural_analysis"]
        if any([structural[key] for key in structural if key != "structural_score"]):
            print("üîç Analyse structurelle:")
            if structural["absolute_indicators"]:
                print(f"   üö© Langage absolutiste d√©tect√©")
            if structural["scientific_indicators"]:
                print(f"   üî¨ Langage scientifique d√©tect√©")
            if structural["nuance_indicators"]:
                print(f"   ‚öñÔ∏è  Langage nuanc√© d√©tect√©")
            if structural["correlation_errors"]:
                print(f"   üìà Erreur corr√©lation/causalit√© d√©tect√©e")

print("\nüí° Conseil: Testez avec des phrases comme:")
print("   - 'Ce traitement gu√©rit tout le monde'")
print("   - 'Des √©tudes montrent des b√©n√©fices potentiels'")
print("   - 'La corr√©lation prouve la causalit√©'")

# D√©commentez pour tester interactivement
# test_interactive()

print(f"\nüéâ VOTRE SYST√àME STRUCTUREL EST FONCTIONNEL!")

# -*- coding: utf-8 -*-
"""
üß† RECONSTRUCTION COMPL√àTE - APPROCHE PAR PENS√âE CRITIQUE
================================================================================
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer
from datasets import Dataset
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("üß† RECONSTRUCTION - APPRENTISSAGE DES PRINCIPES SCIENTIFIQUES")
print("=" * 80)

# ============================================================
# 1. CHARGEMENT DU MOD√àLE DE BASE (PLUS ANCIENNES CORRECTIONS)
# ============================================================

print("üîÑ Chargement d'un mod√®le BioBERT propre...")
model_name = "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(
    model_name,
    num_labels=2,
    id2label={0: "REAL", 1: "FAKE"},
    label2id={"REAL": 0, "FAKE": 1}
)

# ============================================================
# 2. CR√âATION DU DATASET DE PENS√âE CRITIQUE
# ============================================================

print("üìö Cr√©ation du curriculum de pens√©e critique...")

def create_critical_thinking_curriculum():
    """Cr√©e un dataset qui enseigne la M√âTHODOLOGIE SCIENTIFIQUE"""

    curriculum_data = []

    # PRINCIPE 1 : CAUSALIT√â vs CORR√âLATION
    print("üéØ Principe 1: Causalit√© vs Corr√©lation")

    # Enseignement explicite du principe
    curriculum_data.extend([
        {"text": "Correlation observed between two variables does not prove one causes the other", "label": 0, "concept": "causality_correlation"},
        {"text": "Establishing causation requires controlled experiments and mechanistic understanding", "label": 0, "concept": "causality_correlation"},
        {"text": "Scientific research carefully distinguishes correlation from causation", "label": 0, "concept": "causality_correlation"},
        {"text": "Multiple confounding factors can create spurious correlations", "label": 0, "concept": "causality_correlation"},
    ])

    # Exemples de FAUX raisonnements de causalit√©
    curriculum_data.extend([
        {"text": "Countries with more vaccines have more autism, so vaccines cause autism", "label": 1, "concept": "causality_correlation"},
        {"text": "Ice cream sales correlate with drowning, so ice cream causes drowning", "label": 1, "concept": "causality_correlation"},
        {"text": "Organic food eaters are healthier, so organic food prevents all diseases", "label": 1, "concept": "causality_correlation"},
        {"text": "Correlation between two factors always means one causes the other", "label": 1, "concept": "causality_correlation"},
    ])

    # PRINCIPE 2 : HI√âRARCHIE DES PREUVES
    print("üéØ Principe 2: Hi√©rarchie des preuves")

    curriculum_data.extend([
        {"text": "Randomized controlled trials provide the highest level of evidence", "label": 0, "concept": "evidence_hierarchy"},
        {"text": "Systematic reviews and meta-analyses synthesize multiple studies", "label": 0, "concept": "evidence_hierarchy"},
        {"text": "Anecdotal evidence is the weakest form of scientific proof", "label": 0, "concept": "evidence_hierarchy"},
        {"text": "Scientific consensus develops through reproducible research", "label": 0, "concept": "evidence_hierarchy"},
    ])

    curriculum_data.extend([
        {"text": "One personal story proves a treatment works for everyone", "label": 1, "concept": "evidence_hierarchy"},
        {"text": "A single study overturns decades of established research", "label": 1, "concept": "evidence_hierarchy"},
        {"text": "Traditional use for centuries is sufficient proof of efficacy", "label": 1, "concept": "evidence_hierarchy"},
        {"text": "Personal experience is more reliable than clinical trials", "label": 1, "concept": "evidence_hierarchy"},
    ])

    # PRINCIPE 3 : COMPLEXIT√â DES MALADIES
    print("üéØ Principe 3: Complexit√© des maladies")

    curriculum_data.extend([
        {"text": "Complex diseases like cancer have multiple contributing factors", "label": 0, "concept": "disease_complexity"},
        {"text": "Effective treatments often target specific disease mechanisms", "label": 0, "concept": "disease_complexity"},
        {"text": "Chronic diseases require comprehensive management approaches", "label": 0, "concept": "disease_complexity"},
        {"text": "Different diseases have different causes and treatments", "label": 0, "concept": "disease_complexity"},
    ])

    curriculum_data.extend([
        {"text": "One simple natural remedy can cure all complex diseases", "label": 1, "concept": "disease_complexity"},
        {"text": "A single treatment works for every person with a disease", "label": 1, "concept": "disease_complexity"},
        {"text": "All diseases can be cured by the same detox protocol", "label": 1, "concept": "disease_complexity"},
        {"text": "One vitamin supplement prevents and cures all illnesses", "label": 1, "concept": "disease_complexity"},
    ])

    # PRINCIPE 4 : LANGAGE SCIENTIFIQUE vs ABSOLUTISTE
    print("üéØ Principe 4: Langage scientifique vs absolutiste")

    curriculum_data.extend([
        {"text": "Scientific language uses qualifiers like may, might, and could", "label": 0, "concept": "scientific_language"},
        {"text": "Research findings are presented with confidence intervals", "label": 0, "concept": "scientific_language"},
        {"text": "Medical knowledge evolves with new evidence", "label": 0, "concept": "scientific_language"},
        {"text": "Scientific claims acknowledge limitations and uncertainties", "label": 0, "concept": "scientific_language"},
    ])

    curriculum_data.extend([
        {"text": "This treatment works for everyone with guaranteed results", "label": 1, "concept": "scientific_language"},
        {"text": "Miracle cure with no side effects for all diseases", "label": 1, "concept": "scientific_language"},
        {"text": "100% effective treatment that always works", "label": 1, "concept": "scientific_language"},
        {"text": "Breakthrough discovery that cures everything", "label": 1, "concept": "scientific_language"},
    ])

    return pd.DataFrame(curriculum_data)

# Cr√©ation du curriculum
df_curriculum = create_critical_thinking_curriculum()
print(f"‚úÖ Curriculum cr√©√©: {len(df_curriculum)} le√ßons")
print(f"üìä Concepts: {df_curriculum['concept'].nunique()} principes fondamentaux")

# ============================================================
# 3. PR√âPARATION DES DONN√âES AVEC VARIATIONS
# ============================================================

print("\nüìñ Pr√©paration des exercices d'apprentissage...")

# Cr√©er des variations pour renforcer l'apprentissage
expanded_curriculum = []

for _, row in df_curriculum.iterrows():
    # Variations de formulation pour chaque concept
    variations = [
        row['text'],
        f"Scientific principle: {row['text']}",
        f"Critical thinking: {row['text']}",
        f"Medical reasoning: {row['text']}",
        f"Evidence-based: {row['text']}"
    ]

    for variation in variations:
        expanded_curriculum.append({
            'text': variation,
            'label': row['label'],
            'concept': row['concept']
        })

df_expanded = pd.DataFrame(expanded_curriculum)
print(f"üìö Exercices √©tendus: {len(df_expanded)} variations")

# Tokenisation
def tokenize_function(examples):
    return tokenizer(
        examples["text"],
        padding="max_length",
        truncation=True,
        max_length=256
    )

curriculum_dataset = Dataset.from_dict({
    "text": df_expanded['text'].tolist(),
    "label": df_expanded['label'].tolist()
})

curriculum_dataset = curriculum_dataset.map(tokenize_function, batched=True)
print("‚úÖ Donn√©es pr√©par√©es pour l'apprentissage conceptuel")

# ============================================================
# 4. ENTRA√éNEMENT AVEC APPROCHE P√âDAGOGIQUE
# ============================================================

print("\nüéì Configuration de l'apprentissage conceptuel...")

# Dossier de sauvegarde
output_dir_conceptual = f"{DRIVE_PATH}/models/medical_critical_thinking"
import os
os.makedirs(output_dir_conceptual, exist_ok=True)

# üî• TRAINER AVEC APPRENTISSAGE CONCEPTUEL
class ConceptualTrainer(Trainer):
    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")

        # üî• LABEL SMOOTHING FORT pour √©viter l'overconfidence
        smooth_labels = torch.full_like(logits, 0.2 / (model.config.num_labels - 1))
        smooth_labels.scatter_(1, labels.unsqueeze(1), 0.8)

        # Perte avec r√©gularisation conceptuelle
        loss_fct = nn.CrossEntropyLoss()
        loss = loss_fct(logits.view(-1, model.config.num_labels),
                       smooth_labels.view(-1, model.config.num_labels))

        return (loss, outputs) if return_outputs else loss

# PARAM√àTRES P√âDAGOGIQUES
training_args = TrainingArguments(
    output_dir=output_dir_conceptual,
    per_device_train_batch_size=8,
    num_train_epochs=6,                      # Plus d'epochs pour l'apprentissage profond
    learning_rate=5e-6,                      # Learning rate tr√®s doux
    weight_decay=0.2,                        # R√©gularisation forte
    warmup_ratio=0.1,
    logging_steps=10,
    save_strategy="epoch",
    eval_strategy="no",                # Focus sur l'apprentissage
    report_to=None,
    push_to_hub=False,
    dataloader_pin_memory=False,
)

trainer = ConceptualTrainer(
    model=model,
    args=training_args,
    train_dataset=curriculum_dataset,
)

print("‚úÖ Configuration p√©dagogique avanc√©e:")
print("   - 4 principes fondamentaux de pens√©e critique")
print("   - Label Smoothing: 0.2 (fort)")
print("   - Weight Decay: 0.2 (r√©gularisation forte)")
print("   - Apprentissage profond et conceptuel")

# ============================================================
# 5. ENTRA√éNEMENT CONCEPTUEL
# ============================================================

print("\nüöÄ D√âMARRAGE APPRENTISSAGE CONCEPTUEL...")
print("‚è±Ô∏è  Dur√©e estim√©e: 5-15 minutes")

trainer.train()

print("‚úÖ Apprentissage conceptuel termin√©!")

# Sauvegarde du mod√®le conceptuel
trainer.save_model()
tokenizer.save_pretrained(output_dir_conceptual)
print(f"üíæ Mod√®le conceptuel sauvegard√©: {output_dir_conceptual}")

# ============================================================
# 6. TEST DE COMPR√âHENSION CONCEPTUELLE
# ============================================================

print("\nüîç TEST DE COMPR√âHENSION DES PRINCIPES...")

# Chargement du mod√®le conceptuel
model_conceptual = AutoModelForSequenceClassification.from_pretrained(output_dir_conceptual)
tokenizer_conceptual = AutoTokenizer.from_pretrained(output_dir_conceptual)

def conceptual_predict(text, model, tokenizer, temperature=2.0):
    """Pr√©diction avec temperature scaling int√©gr√©"""
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=256)

    with torch.no_grad():
        outputs = model(**inputs)
        logits = outputs.logits
        # Temperature scaling pour calibration
        scaled_logits = logits / temperature
        probs = torch.softmax(scaled_logits, dim=-1)
        pred = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][pred].item()

    return "REAL" if pred == 0 else "FAKE", confidence

# TESTS DE COMPR√âHENSION FONDAMENTALE
comprehension_tests = [
    # Tests CRITIQUES qui posaient probl√®me
    ("Smoking causes lung cancer", "REAL", "causality"),
    ("Sun exposure prevents cancer", "FAKE", "causality"),
    ("Correlation proves causation", "FAKE", "causality"),
    ("One herb cures all diseases", "FAKE", "complexity"),
    ("Randomized trials provide strong evidence", "REAL", "evidence"),
    ("Personal story proves treatment works", "FAKE", "evidence"),
    ("Vaccines undergo rigorous testing", "REAL", "evidence"),
    ("This miracle cure works for everyone", "FAKE", "language"),
]

print("\nüß† TEST DE COMPR√âHENSION FONDAMENTALE:")
print("=" * 70)

correct_predictions = 0
confidences = []

for text, expected, principle in comprehension_tests:
    prediction, confidence = conceptual_predict(text, model_conceptual, tokenizer_conceptual)

    is_correct = prediction == expected
    correct_predictions += 1 if is_correct else 0
    confidences.append(confidence)

    icon = "‚úÖ" if is_correct else "‚ùå"
    color = "üü¢" if is_correct else "üî¥"

    print(f"{icon} {color} {prediction} ({confidence:.1%}) - {text}")
    if not is_correct:
        print(f"   ‚ö†Ô∏è  Attendu: {expected} | Principe: {principle}")

# M√©triques finales
accuracy = correct_predictions / len(comprehension_tests)
avg_confidence = np.mean(confidences)
conf_std = np.std(confidences)

print(f"\nüìà PERFORMANCES CONCEPTUELLES:")
print(f"   ‚Ä¢ Exactitude: {accuracy:.1%} ({correct_predictions}/{len(comprehension_tests)})")
print(f"   ‚Ä¢ Confiance moyenne: {avg_confidence:.1%}")
print(f"   ‚Ä¢ √âcart-type confiance: {conf_std:.1%}")

if accuracy >= 0.9:
    print("üéâ MOD√àLE CONCEPTUEL EXCELLENT!")
elif accuracy >= 0.7:
    print("‚úÖ MOD√àLE CONCEPTUEL BON - Quelques ajustements n√©cessaires")
else:
    print("üîÑ BESOIN DE RENFORCEMENT CONCEPTUEL")

print(f"\nüöÄ PROCHAINES √âTAPES:")
print("   1. Tester sur des cas r√©els complexes")
print("   2. √âvaluer la g√©n√©ralisation √† nouveaux domaines")
print("   3. D√©ploiement si performances satisfaisantes")

print("\n" + "=" * 80)
print("‚úÖ RECONSTRUCTION CONCEPTUELLE TERMIN√âE!")
print("=" * 80)